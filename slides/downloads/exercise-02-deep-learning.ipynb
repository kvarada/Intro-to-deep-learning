{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: Kolhatkar, Varada (2024) [DSCI 572](https://ubc-mds.github.io/DSCI_572_sup-learn-2/README.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer learning** is like borrowing knowledge from one task to help with another: you take a model that has already learned patterns from a related task (e.g., classifying images in [Imagenet](https://www.image-net.org/)) and adapt it to your task (e.g., detecting specific types of fruits) with less effort and data. \n",
    "\n",
    "In this exercise, you will explore transfer learning by leveraging pre-trained image classification models. Specifically, you will:\n",
    "\n",
    "- Use these models out of the box to classify your own images.\n",
    "- Use them as feature extractors to obtain rich representations of your images, which you can then apply to your own tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T18:59:00.811237Z",
     "iopub.status.busy": "2024-12-06T18:59:00.810455Z",
     "iopub.status.idle": "2024-12-06T18:59:06.680311Z",
     "shell.execute_reply": "2024-12-06T18:59:06.679385Z",
     "shell.execute_reply.started": "2024-12-06T18:59:00.811192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Kaggle Kernels\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91yxVPKkO2qa"
   },
   "source": [
    "We are going to run this notebook on the cloud using [Kaggle](https://www.kaggle.com). Kaggle offers 30 hours of free GPU usage per week which should be much more than enough for this lab. To get started, follow these steps:\n",
    "\n",
    "1. Go to https://www.kaggle.com/kernels\n",
    "\n",
    "2. Make an account if you don't have one, and verify your phone number (to get access to GPUs)\n",
    "3. Select `+ New Notebook`\n",
    "4. Go to `File -> Import Notebook`\n",
    "5. Upload this notebook\n",
    "6. On the right-hand side of your Kaggle notebook, make sure:\n",
    "  \n",
    "  - `Internet` is enabled.\n",
    "  \n",
    "  - In the `Accelerator` dropdown, choose `GPU` when you're ready to use it (you can turn it on/off as you need it).\n",
    "    \n",
    "7. Run the follow cells for preparation the model, labels and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T18:59:06.682401Z",
     "iopub.status.busy": "2024-12-06T18:59:06.681909Z",
     "iopub.status.idle": "2024-12-06T18:59:07.833044Z",
     "shell.execute_reply": "2024-12-06T18:59:07.831848Z",
     "shell.execute_reply.started": "2024-12-06T18:59:06.682361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell contains helper functions that will be used later. You don't need to fully understand this code to answer the questions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:02:02.507871Z",
     "iopub.status.busy": "2024-12-06T22:02:02.506962Z",
     "iopub.status.idle": "2024-12-06T22:02:02.527505Z",
     "shell.execute_reply": "2024-12-06T22:02:02.526769Z",
     "shell.execute_reply.started": "2024-12-06T22:02:02.507825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def classify_image(img, topn = 4):\n",
    "    clf = models.vgg16(weights='VGG16_Weights.DEFAULT') # initialize the classifier with VGG16 weights\n",
    "    preprocess = transforms.Compose([\n",
    "                 transforms.Resize(299),\n",
    "                 transforms.CenterCrop(299),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225]),])\n",
    "\n",
    "    with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    clf.eval()\n",
    "    output = clf(batch_t)\n",
    "    _, indices = torch.sort(output, descending=True)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    d = {'Class': [classes[idx] for idx in indices[0][:topn]], \n",
    "         'Probability score': [np.round(probabilities[0, idx].item(),3) for idx in indices[0][:topn]]}\n",
    "    df = pd.DataFrame(d, columns = ['Class','Probability score'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Attribution: [Code from PyTorch docs](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer%20learning)\n",
    "IMAGE_SIZE = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def read_data(data_dir, subdir):\n",
    "    \"\"\"\n",
    "    Reads image data from the specified directory and applies transformations.\n",
    "    \"\"\"\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),     \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),            \n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),                        \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),                        \n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(os.path.join(data_dir, subdir[x]), data_transforms[x])\n",
    "        for x in [\"train\", \"valid\"]\n",
    "    }\n",
    "    \n",
    "    dataloaders = {}\n",
    "    \n",
    "    dataloaders[\"train\"] = torch.utils.data.DataLoader(\n",
    "            image_datasets[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "    \n",
    "    dataloaders[\"valid\"] = torch.utils.data.DataLoader(\n",
    "            image_datasets[\"valid\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "    \n",
    "    return image_datasets, dataloaders\n",
    "\n",
    "def get_features(model, data_loader, seed=None):\n",
    "    \"\"\"Extract output of squeezenet model\"\"\"\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():  # turn off computational graph stuff\n",
    "        Z_init = torch.empty((0, 1024)).to(device)  # Initialize empty tensors\n",
    "        y_init = torch.empty((0)).to(device)\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            Z_init = torch.cat((Z_init, model(X)), dim=0)\n",
    "            y_init = torch.cat((y_init, y))\n",
    "    return Z_init.cpu().detach(), y_init.cpu().detach()\n",
    "\n",
    "def show_predictions(pipe, Z_valid, y_valid, dataloader, class_names, num_images=20, seed=None):\n",
    "    \"\"\"Display images from the validation set and their predicted labels.\"\"\"\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 25))  # Adjust the figure size for better visualization\n",
    "\n",
    "    # Convert the features and labels to numpy arrays\n",
    "    Z_valid = Z_valid.numpy()\n",
    "    y_valid = y_valid.numpy()\n",
    "\n",
    "    # Make predictions using the trained logistic regression model\n",
    "    preds = pipe.predict(Z_valid)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.cpu()\n",
    "            for j in range(inputs.size()[0]):\n",
    "                if images_so_far >= num_images:\n",
    "                    return\n",
    "                # print(f\"Dataloader Labels: {labels[j]}: {class_names['valid'][labels[j]]}\")\n",
    "                ax = plt.subplot(num_images // 5, 5, images_so_far + 1)  # 5 images per row\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"Predicted: {class_names['train'][int(preds[images_so_far])]}\"\n",
    "                             f\"\\nTrue: {class_names['valid'][int(y_valid[images_so_far])]}\")\n",
    "                inp = inputs.data[j].numpy().transpose((1, 2, 0))\n",
    "                mean = np.array([0.5, 0.5, 0.5])\n",
    "                std = np.array([0.5, 0.5, 0.5])\n",
    "                inp = std * inp + mean\n",
    "                inp = np.clip(inp, 0, 1)\n",
    "                ax.imshow(inp)\n",
    "                #imshow(inputs.data[j])\n",
    "                images_so_far += 1\n",
    "\n",
    "def show_image_label_prob(image_path, true_label, num_images):\n",
    "    \"\"\"\n",
    "    Displays a specified number of images from a given directory and prints their classification labels and probabilities.\n",
    "    \"\"\"\n",
    "    images = glob.glob(image_path)\n",
    "    selected_images = random.sample(images, num_images)\n",
    "    plt.figure(figsize=(5, 5));\n",
    "    for image in selected_images:\n",
    "        img = Image.open(image)\n",
    "        img.load()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Actual Label: {true_label}')\n",
    "        plt.show()\n",
    "        df = classify_image(img)    \n",
    "        print(df.to_string(index=False))\n",
    "        print(\"--------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've done all your work on Kaggle, you can download the notebook from Kaggle. That way any work you did on Kaggle won't be lost. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Using pre-trained models out of the box\n",
    "<hr>\n",
    "\n",
    "First, we will use pre-trained Convolutional Neural Network (CNN) models out of the box for image classification. You can find a list of available pre-trained models [here](https://nnabla.readthedocs.io/en/v1.39.0/python/api/models/imagenet.html).\n",
    "\n",
    "In this exercise, we'll use the `VGG16` model to classify cats and dogs using [this dataset](https://www.kaggle.com/datasets/tongpython/cat-and-dog). To get started with the dataset, follow the instructions below.\n",
    "\n",
    "1. Click `+ Add Input` at the top right of the notebook.\n",
    "\n",
    "2. Choose `Datasets`. In the search bar, type 'cat-and-dog'. Several datasets will appear. Locate and add the one with a size of 228MB.\n",
    "\n",
    "Running the following cell will display the image, the model's predictions (`Class`), and the corresponding probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:18:17.984160Z",
     "iopub.status.busy": "2024-12-06T22:18:17.983451Z",
     "iopub.status.idle": "2024-12-06T22:18:35.820756Z",
     "shell.execute_reply": "2024-12-06T22:18:35.819840Z",
     "shell.execute_reply.started": "2024-12-06T22:18:17.984124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "IMAGE_DIR = {\n",
    "    \"Cat\": \"/kaggle/input/cat-and-dog/test_set/test_set/cats/*.*\", \n",
    "    \"Dog\": \"/kaggle/input/cat-and-dog/test_set/test_set/dogs/*.*\"\n",
    "}\n",
    "\n",
    "# Display image and prediction labels with probability\n",
    "for true_label, image_path in IMAGE_DIR.items():\n",
    "    show_image_label_prob(image_path, true_label, num_images=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1 \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Discussion questions**\n",
    "\n",
    "1. How well does the model distinguish between cats and dogs?\n",
    "2. Do you notice any specific patterns or characteristics in the labels?\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:24:07.519575Z",
     "iopub.status.busy": "2024-12-06T22:24:07.518938Z",
     "iopub.status.idle": "2024-12-06T22:24:07.524964Z",
     "shell.execute_reply": "2024-12-06T22:24:07.523830Z",
     "shell.execute_reply.started": "2024-12-06T22:24:07.519539Z"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Type your answer below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you observed reasonable performance on the cats and dogs dataset. Now, let's test the model on a slightly different dataset: [Fruit Classification Dataset](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class). \n",
    "\n",
    "In order to use this dataset \n",
    "\n",
    "1. Click `+ Add Input` at the top right of the notebook.\n",
    "\n",
    "2. Choose `Datasets`. In the search bar, type 'fruit-classification10-class'. Several datasets will appear. Locate and add the one with a size of 31MB.\n",
    "\n",
    "The dataset includes images from the following 10 classes:\n",
    "- Apple\n",
    "- Banana\n",
    "- Avocado\n",
    "- Cherry\n",
    "- Kiwi\n",
    "- Mango\n",
    "- Orange\n",
    "- Pineapple\n",
    "- Strawberries\n",
    "- Watermelon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell will display an image from this dataset, the model's predictions (`Class`), and the corresponding probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:32:16.013339Z",
     "iopub.status.busy": "2024-12-06T22:32:16.012416Z",
     "iopub.status.idle": "2024-12-06T22:32:59.446326Z",
     "shell.execute_reply": "2024-12-06T22:32:59.445445Z",
     "shell.execute_reply.started": "2024-12-06T22:32:16.013288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "IMAGE_DIR = {\n",
    "    \"Apple\": \"/kaggle/input/fruit-classification10-class/MY_data/train/Apple/*.jpeg\", \n",
    "    \"Banana\": \"/kaggle/input/fruit-classification10-class/MY_data/train/Banana/*.jpeg\", \n",
    "    \"Avocado\": \"/kaggle/input/fruit-classification10-class/MY_data/train/avocado/*.jpeg\", \n",
    "    \"Cherry\": \"/kaggle/input/fruit-classification10-class/MY_data/train/cherry/*.jpeg\", \n",
    "    \"Kiwi\": \"/kaggle/input/fruit-classification10-class/MY_data/train/kiwi/*.jpeg\", \n",
    "    \"Mango\": \"/kaggle/input/fruit-classification10-class/MY_data/train/mango/*.jpeg\", \n",
    "    \"Orange\": \"/kaggle/input/fruit-classification10-class/MY_data/train/orange/*.jpeg\", \n",
    "    \"Pineapple\": \"/kaggle/input/fruit-classification10-class/MY_data/train/pinenapple/*.jpeg\", \n",
    "    \"Strawberries\": \"/kaggle/input/fruit-classification10-class/MY_data/train/strawberries/*.jpeg\", \n",
    "    \"Watermelon\": \"/kaggle/input/fruit-classification10-class/MY_data/train/watermelon/*.jpeg\", \n",
    "}\n",
    "\n",
    "# Display image and prediction labels with probability\n",
    "for true_label, image_path in IMAGE_DIR.items():\n",
    "    show_image_label_prob(image_path, true_label, num_images=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Discussion questions**\n",
    "\n",
    "1. How well does the model distinguish between different types of fruits?\n",
    "2. Did you notice any differences in the model's performance between the cats and dogs dataset and the fruits dataset? Briefly explain your answer. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:24:07.519575Z",
     "iopub.status.busy": "2024-12-06T22:24:07.518938Z",
     "iopub.status.idle": "2024-12-06T22:24:07.524964Z",
     "shell.execute_reply": "2024-12-06T22:24:07.523830Z",
     "shell.execute_reply.started": "2024-12-06T22:24:07.519539Z"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Type your answer below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:31:04.573651Z",
     "iopub.status.busy": "2024-11-24T01:31:04.573302Z",
     "iopub.status.idle": "2024-11-24T01:31:04.578075Z",
     "shell.execute_reply": "2024-11-24T01:31:04.577044Z",
     "shell.execute_reply.started": "2024-11-24T01:31:04.573621Z"
    }
   },
   "source": [
    "## Exercise 2: Using pre-trained models as feature extractors\n",
    "\n",
    "<br>\n",
    "\n",
    "Often, we want to train a model on our own datasets and have it predict classes specific to our data, rather than the 1000 classes from ImageNet. To achieve this, we can use pre-trained models as feature extractors. Specifically, we can leverage the rich representations learned by pre-trained models, use these representations as feature vectors, and train a new model on these feature vectors for our specific task.\n",
    "\n",
    "In this exercise, you will use a pre-trained CNN model, `Densenet`, to extract features from images and train a logistic regression classifier to identify different types of fruits.\n",
    "\n",
    "To get started, run the following cell to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:46:16.475227Z",
     "iopub.status.busy": "2024-12-06T22:46:16.474499Z",
     "iopub.status.idle": "2024-12-06T22:46:19.110320Z",
     "shell.execute_reply": "2024-12-06T22:46:19.109607Z",
     "shell.execute_reply.started": "2024-12-06T22:46:16.475193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "DATA_DIR = '/kaggle/input/fruit-classification10-class/MY_data/'\n",
    "SUBDIR = {'train': 'train', 'valid': 'test'}\n",
    "image_datasets, dataloaders = read_data(DATA_DIR, SUBDIR)\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = {\"train\": image_datasets[\"train\"].classes,\n",
    "               \"valid\": image_datasets[\"valid\"].classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look ar some sample images in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:47:00.324779Z",
     "iopub.status.busy": "2024-12-06T22:47:00.323925Z",
     "iopub.status.idle": "2024-12-06T22:47:01.490460Z",
     "shell.execute_reply": "2024-12-06T22:47:01.489593Z",
     "shell.execute_reply.started": "2024-12-06T22:47:00.324740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "inputs, classes = next(iter(dataloaders[\"valid\"]))\n",
    "plt.figure(figsize=(10, 8)); \n",
    "plt.axis(\"off\"); \n",
    "plt.title(\"Sample valid Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(inputs, padding=1, normalize=True),(1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll extract feature vectors from the images above using the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:48:13.996619Z",
     "iopub.status.busy": "2024-12-06T22:48:13.995669Z",
     "iopub.status.idle": "2024-12-06T22:48:23.555801Z",
     "shell.execute_reply": "2024-12-06T22:48:23.554989Z",
     "shell.execute_reply.started": "2024-12-06T22:48:13.996577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download model and extract features\n",
    "model = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "model.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
    "Z_train, y_train = get_features(\n",
    "    model, dataloaders[\"train\"], seed=42\n",
    ")\n",
    "Z_valid, y_valid = get_features(\n",
    "    model, dataloaders[\"valid\"], seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have tabular data. Each example is represented with feature vectors extracted from the `Densenet` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:50:03.866271Z",
     "iopub.status.busy": "2024-12-06T22:50:03.865560Z",
     "iopub.status.idle": "2024-12-06T22:50:03.885775Z",
     "shell.execute_reply": "2024-12-06T22:50:03.884963Z",
     "shell.execute_reply.started": "2024-12-06T22:50:03.866238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Z_train).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a logistic regression model using the extracted features above and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:52:17.594352Z",
     "iopub.status.busy": "2024-12-06T22:52:17.593516Z",
     "iopub.status.idle": "2024-12-06T22:52:32.808634Z",
     "shell.execute_reply": "2024-12-06T22:52:32.806974Z",
     "shell.execute_reply.started": "2024-12-06T22:52:17.594317Z"
    },
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train classification model\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
    "pipe.fit(Z_train, y_train)\n",
    "print(\"Training score: \", pipe.score(Z_train, y_train))\n",
    "pipe.score(Z_valid, y_valid)\n",
    "print(\"Validation score: \", pipe.score(Z_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine some of the predictions made by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T19:02:15.193542Z",
     "iopub.status.busy": "2024-12-06T19:02:15.192081Z",
     "iopub.status.idle": "2024-12-06T19:02:17.622945Z",
     "shell.execute_reply": "2024-12-06T19:02:17.621761Z",
     "shell.execute_reply.started": "2024-12-06T19:02:15.193499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show predictions for 25 images in the validation set (5 rows of 5 images)\n",
    "show_predictions(pipe, Z_valid, y_valid, dataloaders['valid'], class_names, num_images=25, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Discussion questions**\n",
    "\n",
    "1. How well does the model distinguish between different types of fruits?\n",
    "2. Is the performance better than the out-of-the-box performance? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T22:24:07.519575Z",
     "iopub.status.busy": "2024-12-06T22:24:07.518938Z",
     "iopub.status.idle": "2024-12-06T22:24:07.524964Z",
     "shell.execute_reply": "2024-12-06T22:24:07.523830Z",
     "shell.execute_reply.started": "2024-12-06T22:24:07.519539Z"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Type your answer below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Free Time (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks**:\n",
    "\n",
    "Choose any image dataset that interests you and train a model using it!\n",
    "\n",
    "Feel free to discuss your ideas and progress with your teammates and the workshop team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"{_DATA_DIRECTORY_PATH_}\"\n",
    "SUBDIR = \"{_SUB_DIRECTORY_PATH_}\"\n",
    "# Example - dataset `cat-breed-mardhik`\n",
    "# DATA_DIR = '/kaggle/input/cat-breed/cat-breed/'\n",
    "# SUBDIR = {'train': 'TRAIN', 'valid': 'TEST'}\n",
    "\n",
    "# Set up data\n",
    "image_datasets, dataloaders = read_data(DATA_DIR, SUBDIR)\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = {\"train\": image_datasets[\"train\"].classes,\n",
    "               \"valid\": image_datasets[\"valid\"].classes}\n",
    "\n",
    "# Download model and extract features\n",
    "model = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "model.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
    "Z_train, y_train = get_features(\n",
    "    model, dataloaders[\"train\"], seed=42\n",
    ")\n",
    "Z_valid, y_valid = get_features(\n",
    "    model, dataloaders[\"valid\"], seed=42\n",
    ")\n",
    "\n",
    "# Train classification model\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
    "pipe.fit(Z_train, y_train)\n",
    "print(\"Training score: \", pipe.score(Z_train, y_train))\n",
    "pipe.score(Z_valid, y_valid)\n",
    "print(\"Validation score: \", pipe.score(Z_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "show_predictions(pipe, Z_valid, y_valid, dataloaders['valid'], class_names, num_images=25, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 23777,
     "sourceId": 30378,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2529046,
     "sourceId": 4292212,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f821000d0c0da66e5bcde88c37d59c8e0de03b40667fb62009a8148ca49465a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
